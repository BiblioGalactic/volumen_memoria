本地 LLM 的 Collatz 猜想记忆系统
============================================================================================

本文档简要说明了如何将多个数学猜想和定理结合起来，以管理本地语言模型的上下文记忆。目的是在不失去对话可追溯性的情况下避免上下文窗口溢出。

1. **莱文斯坦距离 – 语义度量**

   * 模型的输出被分割为固定大小的片段。
   * 对每个片段估计相似度（莱文斯坦距离）。选择**最独特的**片段和**最常见的**片段。
   * 结果保存到两个临时文件中：`unique_fragment.txt` 包含重复次数最少的片段，而 `common_fragment.txt` 存储最频繁的片段。

2. **Collatz 猜想 – 扩展和收缩动态**

   * 通过为会话中的每个元素（用户输入、助手响应以及选定的独特和常见片段）加 1 来计算*逻辑长度*。
   * 如果总数为**偶数**，记忆将**扩展**：会话最后四次互动保留在记忆文件中。
   * 如果总数为**奇数**，记忆将**收缩**：删除记忆文件的一半（最旧的一半），仅保留最近的互动。

3. **哥德巴赫猜想 – 记忆结构**

   * 应用 Collatz 步骤后，计算记忆文件中的行数。
   * 寻找两个素数，它们的和等于该总数。根据这一素数划分将内容分为两部分，并保留对应于较大素数的片段。这确保记忆始终被分成两个素数长度的片段。

4. **黎曼猜想（操作版本） – 恢复**

   * 如果在上述操作后记忆文件缩减为一行，则使用以前的备份来恢复上一条消息的一半，以补充上下文。概念上它仍被视为单一认知单元，但为了防止突然的信息丢失，会提供更多上下文。

通过这些规则，聊天记忆变得**时间智能**：它保留最近对话的重要部分，以受控方式忘记不再贡献上下文的内容，并且在极端损失的情况下，恢复保持互动连贯所需的最少信息。
